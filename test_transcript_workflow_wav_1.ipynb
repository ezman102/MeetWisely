{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b770832f",
   "metadata": {},
   "source": [
    "# Smart Meeting Assistant - WAV Transcript Processing\n",
    "This notebook transcribes a meeting from an WAV file, performs speaker diarization, generates a summary, translates the content, and extracts action items."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e8e4edbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lightning automatically upgraded your loaded checkpoint from v1.5.4 to v2.5.1. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint C:\\Users\\Oscar\\.cache\\torch\\pyannote\\models--pyannote--segmentation\\snapshots\\c4c8ceafcbb3a7a280c2d357aee9fbc9b0be7f9b\\pytorch_model.bin`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model was trained with pyannote.audio 0.0.1, yours is 3.3.2. Bad things might happen unless you revert pyannote.audio to 0.x.\n",
      "Model was trained with torch 1.10.0+cu102, yours is 2.6.0+cpu. Bad things might happen unless you revert torch to 1.x.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Oscar\\Documents\\GitHub\\MeetWise\\venv\\Lib\\site-packages\\speechbrain\\utils\\parameter_transfer.py:234: UserWarning: Requested Pretrainer collection using symlinks on Windows. This might not work; see `LocalStrategy` documentation. Consider unsetting `collect_in` in Pretrainer to avoid symlinking altogether.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Add the project root to sys.path\n",
    "sys.path.append(os.path.abspath(os.path.join(os.path.dirname(\"__file__\"), \"..\")))\n",
    "\n",
    "import whisper\n",
    "from pyannote.audio import Pipeline\n",
    "from dotenv import load_dotenv\n",
    "from modules.summarizer import generate_summary\n",
    "from modules.translator import translate_text\n",
    "from modules.ds_action_items import extract_action_items_with_deepseek\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# Load models\n",
    "whisper_model = whisper.load_model(\"small\")\n",
    "hf_token = os.getenv(\"HF_TOKEN\")\n",
    "diarization_pipeline = Pipeline.from_pretrained(\"pyannote/speaker-diarization\", use_auth_token=hf_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d44eb45f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transcribe_with_diarization(wav_path):\n",
    "    print(f\"ðŸŽ§ Transcribing {wav_path}...\")\n",
    "\n",
    "    result = whisper_model.transcribe(wav_path)\n",
    "    segments = result.get(\"segments\", [])\n",
    "\n",
    "    diarization = diarization_pipeline(wav_path)\n",
    "    speaker_turns = []\n",
    "    for turn, _, speaker in diarization.itertracks(yield_label=True):\n",
    "        speaker_turns.append({\n",
    "            \"speaker\": speaker,\n",
    "            \"start\": turn.start,\n",
    "            \"end\": turn.end\n",
    "        })\n",
    "\n",
    "    # Debug print\n",
    "    print(\"\\n--- Whisper Segments ---\")\n",
    "    for seg in segments:\n",
    "        print(f\"Whisper: {seg['start']:.2f}s - {seg['end']:.2f}s â†’ {seg['text']}\")\n",
    "\n",
    "    print(\"\\n--- PyAnnote Diarization ---\")\n",
    "    for turn in speaker_turns:\n",
    "        print(f\"PyAnnote: {turn['start']:.2f}s - {turn['end']:.2f}s â†’ {turn['speaker']}\")\n",
    "\n",
    "    # Improved speaker matching\n",
    "    speaker_map = {}\n",
    "    speaker_counter = 1\n",
    "    labeled_lines = []\n",
    "\n",
    "    for seg in segments:\n",
    "        start, end = seg['start'], seg['end']\n",
    "        best_match = None\n",
    "        max_overlap = 0.0\n",
    "\n",
    "        for turn in speaker_turns:\n",
    "            overlap_start = max(start, turn[\"start\"])\n",
    "            overlap_end = min(end, turn[\"end\"])\n",
    "            overlap = max(0.0, overlap_end - overlap_start)\n",
    "\n",
    "            if overlap > max_overlap:\n",
    "                best_match = turn[\"speaker\"]\n",
    "                max_overlap = overlap\n",
    "\n",
    "        matched_speaker = best_match or \"Unknown\"\n",
    "\n",
    "        if matched_speaker not in speaker_map:\n",
    "            speaker_map[matched_speaker] = f\"Speaker {speaker_counter}\"\n",
    "            speaker_counter += 1\n",
    "\n",
    "        readable_speaker = speaker_map[matched_speaker]\n",
    "        labeled_lines.append(f\"[{readable_speaker}] {seg['text'].strip()}\")\n",
    "\n",
    "    return labeled_lines\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3317444",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸŽ§ Transcribing assets/sample_meeting.wav...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Oscar\\Documents\\GitHub\\MeetWise\\venv\\Lib\\site-packages\\whisper\\transcribe.py:115: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
      "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Whisper Segments ---\n",
      "Whisper: 0.00s - 3.60s â†’  Good morning, everyone. Let's get started with today's meeting.\n",
      "Whisper: 4.24s - 7.76s â†’  Sure. The mobile team has completed the login feature.\n",
      "Whisper: 8.44s - 11.04s â†’  I'll test it and provide feedback by Wednesday.\n",
      "Whisper: 11.76s - 14.88s â†’  Great. We also need to finalize the budget proposal.\n",
      "Whisper: 15.48s - 18.44s â†’  I can coordinate with finance and draft the document.\n",
      "Whisper: 19.24s - 21.68s â†’  Please include the updated cost projections.\n",
      "Whisper: 22.44s - 25.04s â†’  Noted. I'll send a draft by Friday.\n",
      "Whisper: 25.84s - 29.16s â†’  Also, don't forget to schedule the stakeholder presentation.\n",
      "Whisper: 29.16s - 31.72s â†’  I'll book a slot for next Monday.\n",
      "\n",
      "--- PyAnnote Diarization ---\n",
      "PyAnnote: 0.03s - 3.61s â†’ SPEAKER_02\n",
      "PyAnnote: 4.32s - 7.47s â†’ SPEAKER_01\n",
      "PyAnnote: 7.47s - 11.20s â†’ SPEAKER_00\n",
      "PyAnnote: 11.83s - 15.02s â†’ SPEAKER_03\n",
      "PyAnnote: 15.57s - 18.53s â†’ SPEAKER_01\n",
      "PyAnnote: 18.53s - 21.77s â†’ SPEAKER_00\n",
      "PyAnnote: 22.49s - 25.26s â†’ SPEAKER_01\n",
      "PyAnnote: 25.87s - 29.28s â†’ SPEAKER_02\n",
      "PyAnnote: 29.95s - 31.98s â†’ SPEAKER_00\n",
      "=== Transcript ===\n",
      "[Speaker 1] Good morning, everyone. Let's get started with today's meeting.\n",
      "[Speaker 2] Sure. The mobile team has completed the login feature.\n",
      "[Speaker 3] I'll test it and provide feedback by Wednesday.\n",
      "[Speaker 4] Great. We also need to finalize the budget proposal.\n",
      "[Speaker 2] I can coordinate with finance and draft the document.\n",
      "[Speaker 3] Please include the updated cost projections.\n",
      "[Speaker 2] Noted. I'll send a draft by Friday.\n",
      "[Speaker 1] Also, don't forget to schedule the stakeholder presentation.\n",
      "[Speaker 3] I'll book a slot for next Monday.\n"
     ]
    }
   ],
   "source": [
    "# Path to WAV file\n",
    "wav_file = \"assets/sample_meeting_1.wav\"\n",
    "\n",
    "# Transcribe and diarize\n",
    "transcript_lines = transcribe_with_diarization(wav_file)\n",
    "\n",
    "# Show transcript\n",
    "print(\"=== Transcript ===\")\n",
    "print(\"\\n\".join(transcript_lines))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "384230d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Summary ===\n",
      "The mobile team has completed the login feature. Speaker 3 will test it and provide feedback by Wednesday. Speaker 2 will draft the budget proposal and send it by Friday. Speaker 1 will schedule the stakeholder presentation for next Monday.   \n"
     ]
    }
   ],
   "source": [
    "# Generate Summary\n",
    "summary = generate_summary(\"\\n\".join(transcript_lines))\n",
    "print(\"=== Summary ===\")\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "26b68928",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Oscar\\Documents\\GitHub\\MeetWise\\venv\\Lib\\site-packages\\huggingface_hub\\file_download.py:896: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Translation (French) ===\n",
      "Bonjour, tout le monde. CommenÃ§ons par la rÃ©union d'aujourd'hui. [Speaker 2] Bien sÃ»r. L'Ã©quipe mobile a terminÃ© la fonction de connexion. [Speaker 3] Je vais la tester et fournir des commentaires d'ici mercredi. [Speaker 4] Super. Nous devons Ã©galement finaliser le projet de budget. [Speaker 2] Je peux coordonner avec la finance et rÃ©diger le document. [Speaker 3] Veuillez inclure les projections de coÃ»ts mises Ã  jour. [Speaker 2] NotÃ©. Je vais envoyer un avant-projet d'ici vendredi. [Speaker 1] Aussi, n'oubliez pas de programmer la prÃ©sentation des intervenants. [Speaker 3] Je vais rÃ©server un crÃ©neau pour lundi prochain.\n"
     ]
    }
   ],
   "source": [
    "# Translate to French\n",
    "translation = translate_text(\"\\n\".join(transcript_lines), src_lang=\"en\", tgt_lang=\"fr\")\n",
    "print(\"=== Translation (French) ===\")\n",
    "print(translation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7a4b0d8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Oscar\\Documents\\GitHub\\MeetWise\\venv\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:492: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.7` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Oscar\\Documents\\GitHub\\MeetWise\\venv\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:497: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Action Items ===\n",
      "Speaker 1:\n",
      "- Schedule the stakeholder presentation\n",
      "\n",
      "Speaker 2:\n",
      "- Test the mobile team's login feature\n",
      "- Draft the budget proposal\n",
      "- Send a draft by Friday\n",
      "\n",
      "Speaker 3:\n",
      "- Test the mobile team's login feature\n",
      "- Provide feedback by Wednesday\n",
      "- Schedule the stakeholder presentation\n",
      "- Book a slot for next Monday\n",
      "\n",
      "Action items are grouped by speaker. Each speaker has their tasks listed, along with any due dates mentioned in the transcript.\n"
     ]
    }
   ],
   "source": [
    "# Extract Action Items\n",
    "action_items = extract_action_items_with_deepseek(transcript_lines)\n",
    "print(\"=== Action Items ===\")\n",
    "print(action_items)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
