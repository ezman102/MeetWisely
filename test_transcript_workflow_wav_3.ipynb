{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b770832f",
   "metadata": {},
   "source": [
    "# Smart Meeting Assistant - WAV Transcript Processing\n",
    "This notebook transcribes a meeting from an WAV file, performs speaker diarization, generates a summary, translates the content, and extracts action items."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8e4edbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Add the project root to sys.path\n",
    "sys.path.append(os.path.abspath(os.path.join(os.path.dirname(\"__file__\"), \"..\")))\n",
    "\n",
    "import whisper\n",
    "from pyannote.audio import Pipeline\n",
    "from dotenv import load_dotenv\n",
    "from modules.summarizer import generate_summary\n",
    "from modules.translator import translate_text\n",
    "from modules.ds_action_items import extract_action_items_with_deepseek\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# Load models\n",
    "whisper_model = whisper.load_model(\"small\")\n",
    "hf_token = os.getenv(\"HF_TOKEN\")\n",
    "diarization_pipeline = Pipeline.from_pretrained(\"pyannote/speaker-diarization\", use_auth_token=hf_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d44eb45f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transcribe_with_diarization(wav_path):\n",
    "    print(f\"ðŸŽ§ Transcribing {wav_path}...\")\n",
    "\n",
    "    result = whisper_model.transcribe(wav_path)\n",
    "    segments = result.get(\"segments\", [])\n",
    "\n",
    "    diarization = diarization_pipeline(wav_path)\n",
    "    speaker_turns = []\n",
    "    for turn, _, speaker in diarization.itertracks(yield_label=True):\n",
    "        speaker_turns.append({\n",
    "            \"speaker\": speaker,\n",
    "            \"start\": turn.start,\n",
    "            \"end\": turn.end\n",
    "        })\n",
    "\n",
    "    # Debug print\n",
    "    print(\"\\n--- Whisper Segments ---\")\n",
    "    for seg in segments:\n",
    "        print(f\"Whisper: {seg['start']:.2f}s - {seg['end']:.2f}s â†’ {seg['text']}\")\n",
    "\n",
    "    print(\"\\n--- PyAnnote Diarization ---\")\n",
    "    for turn in speaker_turns:\n",
    "        print(f\"PyAnnote: {turn['start']:.2f}s - {turn['end']:.2f}s â†’ {turn['speaker']}\")\n",
    "\n",
    "    # Improved speaker matching\n",
    "    speaker_map = {}\n",
    "    speaker_counter = 1\n",
    "    labeled_lines = []\n",
    "\n",
    "    for seg in segments:\n",
    "        start, end = seg['start'], seg['end']\n",
    "        best_match = None\n",
    "        max_overlap = 0.0\n",
    "\n",
    "        for turn in speaker_turns:\n",
    "            overlap_start = max(start, turn[\"start\"])\n",
    "            overlap_end = min(end, turn[\"end\"])\n",
    "            overlap = max(0.0, overlap_end - overlap_start)\n",
    "\n",
    "            if overlap > max_overlap:\n",
    "                best_match = turn[\"speaker\"]\n",
    "                max_overlap = overlap\n",
    "\n",
    "        matched_speaker = best_match or \"Unknown\"\n",
    "\n",
    "        if matched_speaker not in speaker_map:\n",
    "            speaker_map[matched_speaker] = f\"Speaker {speaker_counter}\"\n",
    "            speaker_counter += 1\n",
    "\n",
    "        readable_speaker = speaker_map[matched_speaker]\n",
    "        labeled_lines.append(f\"[{readable_speaker}] {seg['text'].strip()}\")\n",
    "\n",
    "    return labeled_lines\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3317444",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Oscar\\Documents\\GitHub\\MeetWise\\venv\\Lib\\site-packages\\whisper\\transcribe.py:115: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
      "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸŽ§ Transcribing assets/sample_meeting2.wav...\n",
      "\n",
      "--- Whisper Segments ---\n",
      "Whisper: 0.00s - 4.40s â†’  Good morning, everyone. Thanks for joining today's planning session.\n",
      "Whisper: 4.40s - 9.04s â†’  Let's start with a quick check-in. Sarah, could you give us an update on the web dashboard?\n",
      "Whisper: 11.20s - 17.04s â†’  Sure. We completed the new user analytics section last night. The date's pipeline is fully\n",
      "Whisper: 17.04s - 21.60s â†’  integrated now, and we've added co-hard filters based on user segments.\n",
      "Whisper: 21.60s - 26.24s â†’  QA has started testing, and I expect we can deploy to staging by Thursday.\n",
      "Whisper: 26.40s - 34.64s â†’  That's great. On my side, I've been working with the design team on the mobile app layout.\n",
      "Whisper: 34.64s - 41.44s â†’  We've finalized the wireframes for onboarding and user profile pages. Development will begin tomorrow.\n",
      "Whisper: 43.60s - 47.36s â†’  Excellent. And have the localization issues on Android been resolved?\n",
      "Whisper: 49.52s - 53.04s â†’  Not completely. We've fixed the font rendering bug,\n",
      "Whisper: 53.04s - 59.60s â†’  but RTL language alignment still needs adjustment. We're targeting a fix by the end of this sprint.\n",
      "Whisper: 61.92s - 65.52s â†’  Just to add, I reviewed some customer feedback this morning.\n",
      "Whisper: 65.52s - 69.44s â†’  Users in the Middle East specifically mentioned issues with date formatting.\n",
      "Whisper: 69.44s - 72.48s â†’  We should consider auto-detecting locale settings on login.\n",
      "Whisper: 74.88s - 80.00s â†’  That's a good point. I'll loop in the backend team and see if we can integrate locale detection\n",
      "Whisper: 80.00s - 87.04s â†’  with user preferences. Sounds good. Moving on, we have a product demo\n",
      "Whisper: 87.04s - 92.32s â†’  scheduled for next Monday with the leadership team. We'll need everyone to submit their slides by Friday.\n",
      "Whisper: 94.72s - 97.84s â†’  I'll prepare mine by Thursday so the team can review.\n",
      "Whisper: 100.16s - 104.64s â†’  Same here. Also, do we have a final decision on the new pricing tiers?\n",
      "Whisper: 104.88s - 110.08s â†’  Not yet. Finance is still modeling the impact. We'll likely review it early next week.\n",
      "Whisper: 110.08s - 113.12s â†’  Let's keep that as a follow-up item.\n",
      "Whisper: 115.12s - 121.12s â†’  One last thing, the DevOps pipeline has been flaky again. Builds are timing out intermittently.\n",
      "Whisper: 123.12s - 129.12s â†’  I've noticed that too. We may need to upgrade the cRunner or increase the resource limit.\n",
      "Whisper: 129.68s - 133.52s â†’  Please prioritize a fix today. Let me know if you need in for support.\n",
      "Whisper: 133.52s - 139.52s â†’  All right, if there's nothing else, let's wrap. I'll send out the meeting notes and action item shortly.\n",
      "\n",
      "--- PyAnnote Diarization ---\n",
      "PyAnnote: 0.03s - 9.14s â†’ SPEAKER_00\n",
      "PyAnnote: 11.25s - 26.39s â†’ SPEAKER_02\n",
      "PyAnnote: 28.77s - 41.63s â†’ SPEAKER_03\n",
      "PyAnnote: 43.65s - 47.52s â†’ SPEAKER_00\n",
      "PyAnnote: 49.59s - 59.85s â†’ SPEAKER_03\n",
      "PyAnnote: 62.01s - 72.73s â†’ SPEAKER_01\n",
      "PyAnnote: 74.99s - 81.39s â†’ SPEAKER_02\n",
      "PyAnnote: 83.87s - 92.42s â†’ SPEAKER_00\n",
      "PyAnnote: 94.78s - 98.06s â†’ SPEAKER_03\n",
      "PyAnnote: 100.20s - 104.94s â†’ SPEAKER_01\n",
      "PyAnnote: 107.22s - 114.61s â†’ SPEAKER_00\n",
      "PyAnnote: 117.01s - 123.00s â†’ SPEAKER_02\n",
      "PyAnnote: 125.07s - 130.90s â†’ SPEAKER_03\n",
      "PyAnnote: 133.33s - 143.47s â†’ SPEAKER_00\n",
      "=== Transcript ===\n",
      "[Speaker 1] Good morning, everyone. Thanks for joining today's planning session.\n",
      "[Speaker 1] Let's start with a quick check-in. Sarah, could you give us an update on the web dashboard?\n",
      "[Speaker 2] Sure. We completed the new user analytics section last night. The date's pipeline is fully\n",
      "[Speaker 2] integrated now, and we've added co-hard filters based on user segments.\n",
      "[Speaker 2] QA has started testing, and I expect we can deploy to staging by Thursday.\n",
      "[Speaker 3] That's great. On my side, I've been working with the design team on the mobile app layout.\n",
      "[Speaker 3] We've finalized the wireframes for onboarding and user profile pages. Development will begin tomorrow.\n",
      "[Speaker 1] Excellent. And have the localization issues on Android been resolved?\n",
      "[Speaker 3] Not completely. We've fixed the font rendering bug,\n",
      "[Speaker 3] but RTL language alignment still needs adjustment. We're targeting a fix by the end of this sprint.\n",
      "[Speaker 4] Just to add, I reviewed some customer feedback this morning.\n",
      "[Speaker 4] Users in the Middle East specifically mentioned issues with date formatting.\n",
      "[Speaker 4] We should consider auto-detecting locale settings on login.\n",
      "[Speaker 2] That's a good point. I'll loop in the backend team and see if we can integrate locale detection\n",
      "[Speaker 1] with user preferences. Sounds good. Moving on, we have a product demo\n",
      "[Speaker 1] scheduled for next Monday with the leadership team. We'll need everyone to submit their slides by Friday.\n",
      "[Speaker 3] I'll prepare mine by Thursday so the team can review.\n",
      "[Speaker 4] Same here. Also, do we have a final decision on the new pricing tiers?\n",
      "[Speaker 1] Not yet. Finance is still modeling the impact. We'll likely review it early next week.\n",
      "[Speaker 1] Let's keep that as a follow-up item.\n",
      "[Speaker 2] One last thing, the DevOps pipeline has been flaky again. Builds are timing out intermittently.\n",
      "[Speaker 3] I've noticed that too. We may need to upgrade the cRunner or increase the resource limit.\n",
      "[Speaker 3] Please prioritize a fix today. Let me know if you need in for support.\n",
      "[Speaker 1] All right, if there's nothing else, let's wrap. I'll send out the meeting notes and action item shortly.\n"
     ]
    }
   ],
   "source": [
    "# Path to WAV file\n",
    "wav_file = \"assets/sample_meeting.wav\"\n",
    "\n",
    "# Transcribe and diarize\n",
    "transcript_lines = transcribe_with_diarization(wav_file)\n",
    "\n",
    "# Show transcript\n",
    "print(\"=== Transcript ===\")\n",
    "print(\"\\n\".join(transcript_lines))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "384230d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Summary ===\n",
      "Speaker 1 will send out the meeting notes and action item shortly. Sarah gives an update on the web dashboard. QA has started testing and she expects it to be ready for staging by Thursday. On speaker 2's side, he's been working on the design of the mobile app layout. Speaker 3 has finalized the wireframes for onboarding and user profile pages. The localization issues on Android haven't been resolved yet. The DevOps pipeline is flaky again. The product demo is scheduled for next Monday.\n"
     ]
    }
   ],
   "source": [
    "# Generate Summary\n",
    "summary = generate_summary(\"\\n\".join(transcript_lines))\n",
    "print(\"=== Summary ===\")\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "26b68928",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Oscar\\Documents\\GitHub\\MeetWise\\venv\\Lib\\site-packages\\huggingface_hub\\file_download.py:896: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Translation (French) ===\n",
      "[Speaker 1] Merci d'avoir rejoint la session de planification d'aujourd'hui. [Speaker 1] CommenÃ§ons par un check-in rapide. Sarah, pourriez-vous nous donner une mise Ã  jour sur le tableau de bord web? [Speaker 2] Bien sÃ»r. Nous avons terminÃ© la nouvelle section d'analyse d'utilisateur hier soir. [Speaker 3] Le pipeline de la date est entiÃ¨rement intÃ©grÃ© [Speaker 2], et nous avons ajoutÃ© des filtres co-dur basÃ©s sur des segments d'utilisateur. [Speaker 3] QA a commencÃ© Ã  tester, et je m'attends Ã  ce que nous puissions dÃ©ployer un nouveau produit avant jeudi. [Speaker 3] C'est gÃ©nial. De mon cÃ´tÃ©, j'ai travaillÃ© avec l'Ã©quipe de conception sur la mise en page de l'application mobile. [Speaker 3] Nous avons finalisÃ© les images filaires pour les pages d'affichage et de profil utilisateur.\n"
     ]
    }
   ],
   "source": [
    "# Translate to French\n",
    "translation = translate_text(\"\\n\".join(transcript_lines), src_lang=\"en\", tgt_lang=\"fr\")\n",
    "print(\"=== Translation (French) ===\")\n",
    "print(translation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7a4b0d8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Oscar\\Documents\\GitHub\\MeetWise\\venv\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:492: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.7` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Oscar\\Documents\\GitHub\\MeetWise\\venv\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:497: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Action Items ===\n",
      "Speaker 1:\n",
      "- Send out meeting notes and action items\n",
      "- Follow up on new pricing tiers\n",
      "\n",
      "Speaker 2:\n",
      "- Deploy web dashboard to staging by Thursday\n",
      "- Integrate locale detection with user preferences\n",
      "\n",
      "Speaker 3:\n",
      "- Prepare product demo slides by Thursday\n",
      "- Develop mobile app layout beginning tomorrow\n",
      "\n",
      "Speaker 4:\n",
      "- Submit product demo slides by Friday\n",
      "- Consider auto-detecting locale settings on login\n"
     ]
    }
   ],
   "source": [
    "# Extract Action Items\n",
    "action_items = extract_action_items_with_deepseek(transcript_lines)\n",
    "print(\"=== Action Items ===\")\n",
    "print(action_items)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
